{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Approximate Algorithms Overview: Variational Inference and Sampling Methods (Markov Chain Monte Carlo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Two approximate algorithms:\n",
    "- Sampling methods: repeatedly generate random numbers\n",
    "    - traditional method\n",
    "    - find a globally optimal solution\n",
    "    - Time-consuming\n",
    "    - Appropriate sampling technique such as Gibbs sampling\n",
    "- Variational inference methods: optimization problem\n",
    "    - emerged over the past 15 years\n",
    "    - alternative approach\n",
    "    - almost never find global optimal solution\n",
    "    - know convergence or not\n",
    "    - have bounds on accuracy\n",
    "    - parallelization over multiple processors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Variational Inference (VI)\n",
    "### Inference as optimization\n",
    "- cast inference as an optimization problem;\n",
    "- solve an optimization problem over a class of tractable distributions Q in order to find a q∈Q that is most similar to p, our interested probability distribution, then query q to get an approximate solution.\n",
    "- choose an approximating family Q and an optimization objective J(q) to capture the similarity between q and p."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Features (advantages)\n",
    "- fast (both user time and computing time)\n",
    "- reliable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### The Kullback-Leibler divergence (KL divergence)\n",
    "$KL(q||p) = \\sum_x q(x)\\log\\frac{q(x)}{p(x)}$\n",
    "- measure differences in information contained within two distributions.\n",
    "- properties of KL divergence\n",
    "    - $KL(q||p) \\ge 0$ for all $q,p$\n",
    "    - $KL(q||p)=0$ if and only if $q=p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The optimization objective J(q)\n",
    "\n",
    "$J(q) = \\sum_x q(x)\\log\\frac{q(x)}{\\tilde{p}(x)}$ \\\n",
    "     $= \\sum_x q(x)\\log\\frac{q(x)}{p(x)}-\\log{Z(\\theta)}$ \\\n",
    "     $= KL(q||p) - \\log Z(\\theta)$\n",
    "     \n",
    "$\\Longrightarrow $\n",
    "\n",
    "$\\log Z(\\theta) = KL(q||p) - J(q) \\ge - J(q)$\n",
    "\n",
    "$- J(q)$: lower bound on function $\\log Z(\\theta)$\n",
    "- also called variational lower bound or the evidence lower bound (ELBO)\n",
    "- **maximizing** the evidence-lower bound leads to **minimizing** the divergence $KL(q‖p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Sampling methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Markov chain Monte Carlo (MCMC)\n",
    "- Markov Chain\n",
    "\n",
    "A sequence of random variables with each random variable Si∈{1,2,…,d} represents the state of a system. The initial state is distributed according to a probability, all subsequent states are generated from a conditional probability distribution that depends only on the previous random state. i.e., the transition probabilities at any time depend only on the given state and not on the history.\n",
    "\n",
    "- transition probability\n",
    "\n",
    "A d×d matrix\n",
    "\n",
    "- stationary distribution\n",
    "    - Irreducibility: any state x to any other state x′ with probability > 0 in a finite number of steps\n",
    "    - Aperiodicity: return to any state at any time\n",
    "\n",
    "\n",
    "- Steps\n",
    "    - Run the Markov chain from $x_0$ for B burn-in steps.\n",
    "    - Run the Markov chain for N sampling steps and collect all the states that it visits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Gibbs sampling\n",
    "A MCMC algorithm for obtaining a sequence of observations when direct sampling is difficult.\n",
    "\n",
    "Repeat until convergence for t=1,2,…:\n",
    "- Set $x←x^{t−1}$;\n",
    "- For each variable $x_i$ in the order we fixed:\n",
    "    - Sample $x'_{i} \\sim p(x_i | x_{-i})$\n",
    "    - Update $x←(x_1,…,x'_i,…,x_n)$\n",
    "- Set $x^t ← x$\n",
    "\n",
    "$x_{-i}$: all variables in $x$ except $x_i$.\n",
    "\n",
    "As updating $x_i$, we immediately use its new value for sampling other variables $x_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Running time\n",
    "- MCMC running time may be extremely long, in other words, the convergence will be very slow. \n",
    "- Not sure when to end the burn-in period. Solution: plot certain quantities and estimating them by eye."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Summary\n",
    "- MCMC can sample from the correct distribution, but require very long time and difficult to judge the amount of computation that we need to spend to find a good solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.21.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
